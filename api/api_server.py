# api/api_server.py
from fastapi import FastAPI, HTTPException, Query, Request, Path, Body
from pydantic import BaseModel, Extra

from batch import BatchPipeline
from batch import PipelineManager
from tests.test_result_mqtt_pipeline import pipeline
from typing import List, Literal, Optional, Dict, Any
import pandas as pd
import json
from config import ConfigProvider, config_manager
from config import ConfigManager
from validation.gx_init import GXInitializer


app = FastAPI(title="Data Ingestion API")

class LoosePayload(BaseModel):
    """
    A catch-all payload model that allows any extra fields.
    """
    class Config:
        extra = Extra.allow

@app.post("/ingest/{topic}")
async def ingest_data_item(
    payload: LoosePayload,
    request: Request,
    topic: str = Path(..., description="MQTT topic, e.g. /air-quality")
):
    """
    Receives POSTs to /ingest/{topic}, where:
      - `topic` is taken from the URL path (supports slashes via `{topic:path}`).
      - `payload` is any JSON object, with fields dynamically allowed.
    Dispatches into the same BatchPipeline(s) as MQTT.
    """
    manager = request.app.state.manager
    ok = manager.dispatch(topic, payload.dict())
    if not ok:
        raise HTTPException(status_code=404, detail=f"No pipeline for topic '{topic}'")
    return {"status": "queued", "topic": topic}




@app.post("/ingest/{topic}/sync")
async def ingest_data_batch(
    request: Request,
    topic: str = Path(..., description="MQTT topic, e.g. /air-quality"),
    config_id: str = Query(None, description="Optional config ID to use for processing"),
    payloads: List[LoosePayload] = Body(
        ..., 
        description="Array of records to process"
    ),
):

    config_name = f"{config_id}_{topic}"
    pipeline = BatchPipeline(topic, config_name, batch_size=1) # batch size of 1 for synchronous processing irrelevant

    # Convert your Pydantic models into plain dicts
    raw_dicts = [p.dict() for p in payloads]
    df = pd.DataFrame(raw_dicts)

    

    # Run your synchronous processing
    cleaned_df = pipeline.process_sync(df)
    cleaned = json.loads(cleaned_df.to_json(orient="records"))

    return {
        "status": "processed",
        "topic": topic,
        "count": len(cleaned),
        "cleaned": cleaned,
    }



@app.get("/configs/{cfg_type}", 
         summary="List configurations",
        description="Retrieve configurations filtered by kind. Use pagination via limit/offset.")
async def get_configs(
    cfg_type: Optional[Literal["mqtt", "validation"]] = Path(..., description="Filter to a specific config type")
):
    """
    Return the currently saved configurations from disk.

    - type=mqtt        -> all JSON files in 'config/' (mapping: filename -> content)
    - type=validation  -> all JSON files in 'config/validations/'
    - (no type)        -> both, as { "mqtt": {...}, "validation": {...} }
    """
    try:
        provider = ConfigProvider()

        if cfg_type == "mqtt":
            mqtt_cfg = provider.mqtt() 
            return {"mqtt": mqtt_cfg}

        if cfg_type == "validation":
            validation_cfg = provider.validation() 
            return {"validation": validation_cfg}

        # default: both
        mqtt_cfg = provider.mqtt()
        validation_cfg = provider.validation()
        return {"mqtt": mqtt_cfg, "validation": validation_cfg}

    except FileNotFoundError as e:
        raise HTTPException(status_code=404, detail={str(e)})
    except json.JSONDecodeError as e:
        # surface which file was malformed if available
        raise HTTPException(status_code=422, detail=f"Invalid JSON in config files: {e}")
    
@app.post("/configs/{cfg_type}")
@app.post("/configs/{cfg_type}/{cfg_id}")
async def ingest_config(
    request: Request,
    cfg_type: Literal["mqtt", "validation"],
    payload: Dict[str, Any] = Body(...),
    cfg_id: str | None = None,   # <-- just a plain optional argument
):

    config_manager = ConfigManager(base_path="config")
    
    try:
        target = config_manager.write_atomic(cfg_type, cfg_id, payload)
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to write config: {e}")
    

    # reload gx and pipelines
    try:
        provider = ConfigProvider()

        if cfg_type == "mqtt":
            request.app.state.manager.reload_from_provider(provider)
        elif cfg_type == "validation":
            gx_initializer: GXInitializer =  request.app.state.gx
            gx_initializer.reload_gx()
        else:
            raise HTTPException(status_code=400, detail="Invalid configuration type. Use 'mqtt' or 'validation'.")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to reload configurations: {e}")
    

    return {
        "status": "Configuration saved",
        "type": cfg_type
    }


@app.delete("/configs/{cfg_type}/{cfg_id}",
            summary="Delete a configuration",
            description="Delete a specific configuration by type and ID.")
async def delete_config(
    request: Request,
    cfg_type: Literal["mqtt", "validation"] = Path(..., description="Type of configuration to delete"),
    cfg_id: Optional[str] = Path(..., description="ID of the configuration to delete (file stem for validation)")
):
    # only allow deleting a single configuration state file
    if cfg_type not in ["mqtt", "validation"]:
        raise HTTPException(status_code=400, detail="Invalid configuration type. Use 'mqtt' or 'validation'.")
    if cfg_type == "validation" and not cfg_id:
        raise HTTPException(status_code=400, detail="Validation config requires a file-stem in the path.")
    if cfg_type == "mqtt":
        # keep this explicit for now; you can enable later if desired
        raise HTTPException(status_code=400, detail="MQTT config deletion is disabled via this endpoint.")

    manager = ConfigManager(base_path="config")
    try:
        removed_paths = manager.delete("validation", cfg_id, missing_ok=False, pipelines = request.app.state.manager.pipelines)
    except FileNotFoundError as e:
        raise HTTPException(status_code=404, detail=str(e))
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to delete config: {e}")

    # reload GX after modification to validation states
    try:
        gx = request.app.state.gx
        gx.reload_gx()
    except AttributeError:
        raise HTTPException(status_code=500, detail="GX initializer missing on app.state (app.state.gx).")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to reload GX after deletion: {e}")

    return {
        "status": "deleted",
        "type": cfg_type,
        "gx_reloaded": True,
    }